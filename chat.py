import streamlit as st
import pandas as pd
import numpy as np
import torch
from transformers import AutoTokenizer, AutoModel
import faiss
from fuzzywuzzy import process
import re

# --- Load PhoBERT ---
@st.cache_resource
def load_phobert():
    tokenizer = AutoTokenizer.from_pretrained("vinai/phobert-base", cache_dir="./phobert_cache")
    model = AutoModel.from_pretrained("vinai/phobert-base", cache_dir="./phobert_cache")
    return tokenizer, model

# --- Embedding ---
def get_embedding(text, _tokenizer, _model):
    if text is None: return None
    inputs = _tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=128)
    with torch.no_grad():
        outputs = _model(**inputs)
    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()

# --- Chuáº©n hÃ³a ---
def normalize_column(series):
    mapping = {
        "Ä‘áº¡i sá»‘": "Äáº¡i sá»‘", "Ä‘ai sá»‘": "Äáº¡i sá»‘",
        "hÃ¬nh há»c": "HÃ¬nh há»c", "hÃŒnh há»c": "HÃ¬nh há»c",
        "bÃ i táº­p": "BÃ i táº­p", "bÃ i táº­p ": "BÃ i táº­p",
        "bÃ i táº­p tráº¯c nghiá»‡m": "BÃ i táº­p tráº¯c nghiá»‡m",
        "lÃ½ thuyáº¿t": "LÃ½ thuyáº¿t"
    }
    return series.fillna("").apply(lambda x: mapping.get(str(x).strip().lower(), str(x).strip()))

# --- Load dá»¯ liá»‡u ---
@st.cache_data
def load_data(csv_path):
    df = pd.read_csv(csv_path)
    df["CÃ¢u há»i"] = df["CÃ¢u há»i"].astype(str).str.strip()
    df["CÃ¢u tráº£ lá»i"] = df["CÃ¢u tráº£ lá»i"].astype(str).str.strip()
    df = df.dropna(subset=["CÃ¢u há»i", "CÃ¢u tráº£ lá»i"])
    df["Chá»§ Ä‘á»"] = normalize_column(df["Chá»§ Ä‘á»"])
    df["Thá»ƒ loáº¡i"] = normalize_column(df["Thá»ƒ loáº¡i"])
    df["Lá»›p"] = df["Lá»›p"].astype(str).str.strip()
    return df

# --- FAISS Index ---
@st.cache_resource
def build_faiss_index(df, _tokenizer, _model):
    embeddings, valid_idx = [], []
    for i, row in df.iterrows():
        emb = get_embedding(row["CÃ¢u há»i"], _tokenizer, _model)
        if emb is not None:
            embeddings.append(emb)
            valid_idx.append(i)
    index = faiss.IndexFlatL2(len(embeddings[0]))
    index.add(np.array(embeddings).astype('float32'))
    return index, valid_idx

# --- Fuzzy Matching ---
def fuzzy_match(query, df):
    best = process.extractOne(query, df["CÃ¢u há»i"].tolist())
    if best:
        matched = df[df["CÃ¢u há»i"] == best[0]].iloc[0]
        return matched["CÃ¢u tráº£ lá»i"], matched.get("HÆ°á»›ng dáº«n giáº£i", ""), best[1]
    return "KhÃ´ng tÃ¬m tháº¥y", "", 0

# --- TÃ­nh toÃ¡n biá»ƒu thá»©c toÃ¡n há»c ---
def evaluate_expression(query):
    try:
        result = eval(query, {"__builtins__": {}})
        return result
    except Exception:
        return None

# --- Tráº¡ng thÃ¡i há»™i thoáº¡i ---
if "messages" not in st.session_state:
    st.session_state.messages = []
    st.session_state.stage = "start"
    st.session_state.grade = ""
    st.session_state.topic = ""
    st.session_state.type = ""
    st.session_state.quiz_row = None

# --- Load mÃ´ hÃ¬nh & dá»¯ liá»‡u ---
tokenizer, model = load_phobert()
df = load_data("Toan.csv")
index, valid_idx = build_faiss_index(df, tokenizer, model)

# --- Giao diá»‡n ---
st.title("ğŸ“š Chatbot ToÃ¡n há»c")
st.markdown("Nháº­p cÃ¢u há»i lÃ½ thuyáº¿t, biá»ƒu thá»©c toÃ¡n há»c hoáº·c gÃµ **`HÃ£y cho tÃ´i bÃ i táº­p`** Ä‘á»ƒ báº¯t Ä‘áº§u.")
if st.button("ğŸ§¹ XÃ³a há»™i thoáº¡i"):
    st.session_state.messages = []
    st.session_state.stage = "start"
    st.session_state.grade = ""
    st.session_state.topic = ""
    st.session_state.type = ""
    st.session_state.quiz_row = None
    st.rerun()

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

query = st.chat_input("Nháº­p cÃ¢u há»i hoáº·c yÃªu cáº§u bÃ i táº­p...")

if query:
    with st.chat_message("user"):
        st.markdown(query)
    st.session_state.messages.append({"role": "user", "content": query})

    # === Luá»“ng bÃ i táº­p ===
    if st.session_state.stage == "start" and "bÃ i táº­p" in query.lower():
        st.session_state.stage = "ask_grade"
        msg = "ğŸ“Œ Báº¡n muá»‘n chá»n **lá»›p máº¥y**?"

    elif st.session_state.stage == "ask_grade":
        st.session_state.grade = query.strip()
        st.session_state.stage = "ask_topic"
        msg = "ğŸ“˜ Báº¡n muá»‘n chá»n **chá»§ Ä‘á»** nÃ o? _(Äáº¡i sá»‘ / HÃ¬nh há»c)_"

    elif st.session_state.stage == "ask_topic":
        st.session_state.topic = query.strip()
        st.session_state.stage = "ask_type"
        msg = "ğŸ“— Báº¡n muá»‘n chá»n **thá»ƒ loáº¡i** nÃ o? _(BÃ i táº­p / BÃ i táº­p tráº¯c nghiá»‡m / LÃ½ thuyáº¿t)_"

    elif st.session_state.stage == "ask_type":
        st.session_state.type = query.strip()
        df_filtered = df[
            (df["Lá»›p"] == st.session_state.grade) &
            (df["Chá»§ Ä‘á»"].str.lower() == st.session_state.topic.lower()) &
            (df["Thá»ƒ loáº¡i"].str.lower() == st.session_state.type.lower())
        ]
        if not df_filtered.empty:
            row = df_filtered.sample(1).iloc[0]
            st.session_state.quiz_row = row
            st.session_state.stage = "answer_quiz"
            msg = f"ğŸ“ **CÃ¢u há»i**: {row['CÃ¢u há»i']}"
        else:
            st.session_state.stage = "start"
            msg = "âŒ KhÃ´ng tÃ¬m tháº¥y bÃ i táº­p phÃ¹ há»£p. Vui lÃ²ng thá»­ láº¡i."

    elif st.session_state.stage == "answer_quiz":
        user_ans = query.strip().lower()
        correct = st.session_state.quiz_row["CÃ¢u tráº£ lá»i"].strip().lower()
        if user_ans == correct:
            msg = "âœ… ChÃ­nh xÃ¡c!"
        else:
            msg = f"âŒ ChÆ°a Ä‘Ãºng. ÄÃ¡p Ã¡n Ä‘Ãºng lÃ : **{st.session_state.quiz_row['CÃ¢u tráº£ lá»i']}**"
            if pd.notna(st.session_state.quiz_row.get("HÆ°á»›ng dáº«n giáº£i", "")):
                msg += f"\nğŸ“– **HÆ°á»›ng dáº«n giáº£i**: {st.session_state.quiz_row['HÆ°á»›ng dáº«n giáº£i']}"
        st.session_state.stage = "start"

    # === Luá»“ng lÃ½ thuyáº¿t ===
    elif st.session_state.stage == "start":
        if re.fullmatch(r"[0-9\s\+\-\*/().]+", query.strip()):
            result = evaluate_expression(query)
            if result is not None:
                msg = f"ğŸ§® Káº¿t quáº£ cá»§a biá»ƒu thá»©c `{query}` lÃ : **{result}**"
            else:
                msg = f"âš ï¸ KhÃ´ng thá»ƒ tÃ­nh toÃ¡n biá»ƒu thá»©c: `{query}`"
        else:
            emb = get_embedding(query, tokenizer, model)
            D, I = index.search(np.array([emb]).astype("float32"), 1)
            if D[0][0] > 1.0:
                ans, hint, score = fuzzy_match(query, df)
                msg = f"**Fuzzy Matching ({score}%)**\n\nğŸ§  {ans}"
                if pd.notna(hint) and hint.strip():
                    msg += f"\nğŸ“– **HÆ°á»›ng dáº«n giáº£i**: {hint}"
            else:
                row = df.iloc[valid_idx[I[0][0]]]
                msg = f"ğŸ§  **{row['CÃ¢u tráº£ lá»i']}**"
                if pd.notna(row.get("HÆ°á»›ng dáº«n giáº£i", "")):
                    msg += f"\nğŸ“– **HÆ°á»›ng dáº«n giáº£i**: {row['HÆ°á»›ng dáº«n giáº£i']}"

    with st.chat_message("assistant"):
        st.markdown(msg)
    st.session_state.messages.append({"role": "assistant", "content": msg})
